{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e3e97ae",
   "metadata": {},
   "source": [
    "# **Anime recommendation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2da51e",
   "metadata": {},
   "source": [
    "+ Alexander Sanchez Sanchez\n",
    "+ Juan David Cruz Garcia\n",
    "+ Juan Sebastian Perez Camacho\n",
    "+ Kennet Santiago Sanchez Roldan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc13426",
   "metadata": {},
   "source": [
    "### El objetivo de este proyecto es construir un modelo de inteligencia artificial que sea capaz de recomendar animes a usuarios segun que animes hayan visto estos previamente y la calificacion dada.\n",
    "### La informacion utilizada aqui es extraida de Kaggle desde el enlace: https://www.kaggle.com/datasets/CooperUnion/anime-recommendations-database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadab364",
   "metadata": {},
   "source": [
    "## Carga de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb18629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt    #Importamos pyplot de librería matplotlib. Lo vamos a utilizar para graficar.\n",
    "import seaborn as sns              #Importamos la librería Seaborn. La vamos a utilizar para graficar.\n",
    "import numpy as np                 #Importamos la librería numpy para manipular arreglos.\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split #Útil para dividir los conjuntos de datos. \n",
    "from sklearn.preprocessing import MinMaxScaler       #Útil para escalar los atributos de entrada.\n",
    "\n",
    "from copy import deepcopy                            #Permite hacer copias profundas. \n",
    "\n",
    "from sklearn.cluster import KMeans                   #Clase que implementa k-means.\n",
    "from sklearn.metrics import silhouette_samples       #Útil para calcular el valor de la silueta de una observación. \n",
    "from sklearn.metrics import silhouette_score         #Útil para calcular el valor de la silueta de todas las observaciones.\n",
    "from sklearn.metrics import calinski_harabasz_score  #Útil para calcular el valor del índice Calinski Harabasz (CH).\n",
    "from sklearn.metrics import confusion_matrix         #Permite extraer la matriz de confusión.\n",
    "from sklearn import neighbors                        #Permite utilizar el algoritmo de vecinos más cercanos.\n",
    "\n",
    "#!pip install yellowbrick --upgrade                  #Instala y actualiza la librería yellowbrick (la versión por defecto en Google Colab está desactualizada).\n",
    "from yellowbrick.cluster import KElbowVisualizer     #Permite obtener la gráfica del codo para tres métricas diferentes (distorsión, silueta, CH).\n",
    "from yellowbrick.cluster import SilhouetteVisualizer \n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ca42a2",
   "metadata": {},
   "source": [
    "## **Carga de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac3e6fba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\User\\\\Desktop\\\\AI-anime-recomendation/datos/anime.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mabsolute())\n\u001b[0;32m      4\u001b[0m path \u001b[38;5;241m=\u001b[39m path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/datos/anime.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 5\u001b[0m dfAnime \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m   \n\u001b[0;32m      6\u001b[0m dfAnime\u001b[38;5;241m.\u001b[39minfo()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\User\\\\Desktop\\\\AI-anime-recomendation/datos/anime.csv'"
     ]
    }
   ],
   "source": [
    "#Anime.csv\n",
    "path = Path(os.getcwd())\n",
    "path = str(path.parent.absolute())\n",
    "path = path+\"/datos/anime.csv\"\n",
    "dfAnime = pd.read_csv(path,na_values='?')   \n",
    "dfAnime.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b536cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rating.csv\n",
    "path2 = Path(os.getcwd())\n",
    "path2 = str(path2.parent.absolute())\n",
    "path2 = path2+\"/datos/rating.csv\"\n",
    "dfRating = pd.read_csv(path2,na_values='?')   \n",
    "dfRating.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4507dfd",
   "metadata": {},
   "source": [
    "## **Tipos de dato adecuados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbd02d1",
   "metadata": {},
   "source": [
    "**Definimos tipos para cada columna del dataframe que tenga como tipo \"object\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abda122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#anime.csv\n",
    "dfAnime['name'] = dfAnime['name'].astype(\"string\")\n",
    "dfAnime['genre'] = dfAnime['genre'].astype(\"string\")\n",
    "dfAnime['type'] = dfAnime['type'].astype(\"string\")\n",
    "dfAnime['episodes']=pd.to_numeric(dfAnime.episodes, errors='coerce').dropna().astype(int)\n",
    "dfAnime.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956d81e3",
   "metadata": {},
   "source": [
    " **rating.csv ya tenia los tipos de datos adecuados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ded0935",
   "metadata": {},
   "source": [
    "## **Busqueda y eliminacion de valores nulos o duplicados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d37ec",
   "metadata": {},
   "source": [
    "**Vamos a buscar los valores nulos de los dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41f3829",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# anime.csv\n",
    "print(\"La cantidad de datos nulos es:\")\n",
    "dfAnime.isna().sum().to_frame().T.style.set_properties(**{\"background-color\": \"#2a9d8f\",\"color\":\"white\",\"border\": \"1.5px  solid black\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cbb7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating.csv\n",
    "print(\"La cantidad de datos nulos es:\")\n",
    "dfRating.isna().sum().to_frame().T.style.set_properties(**{\"background-color\": \"#2a9d8f\",\"color\":\"white\",\"border\": \"1.5px  solid black\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e614b94d",
   "metadata": {},
   "source": [
    "+ **La cantidad de datos con valores nulos no es tan grande en comparacion al total asi que podemos borrarlos.**\n",
    "+ **Eliminamos tambien los valores innecesarios. (En el caso de rating.csv, los rating con -1 son inutiles para nuestro problema puesto que simbolizan que el usuario no ha calificado el anime)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb14bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnime=dfAnime.dropna()\n",
    "dfRating = dfRating[dfRating.rating != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f05f4e",
   "metadata": {},
   "source": [
    "**Ahora buscamos el numero de datos duplicados y eliminamos en caso de que existan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e2cbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Anime.csv\n",
    "duplicados = dfAnime[dfAnime.duplicated()].shape[0]\n",
    "print(\"Numero de datos duplicados \",duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839cb511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating.csv\n",
    "duplicados = dfRating[dfRating.duplicated()].shape[0]\n",
    "print(\"Numero de datos duplicados \",duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55872b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating.csv\n",
    "dfRating.drop_duplicates(keep='first',inplace=True)\n",
    "duplicados = dfRating[dfRating.duplicated()].shape[0]\n",
    "print(\"Numero de datos duplicados \",duplicados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cf006d",
   "metadata": {},
   "source": [
    "## Ajustes para el dataframe anime.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55201b56",
   "metadata": {},
   "source": [
    "+ **Convertimos \"episodes\" en una variable de numeros enteros para poder realizar adecuadamente el conteo**\n",
    "+ **Convertimos \"type\" en una variable de tipo categoria para poder realizar analisis sobre este**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2affe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAnime['episodes'] = dfAnime['episodes'].astype(int)\n",
    "dfAnime=dfAnime.replace({'Movie': '0', 'TV': '1','OVA':'2','ONA':'2','Special':'3','Music':'4'})\n",
    "dfAnime['type'] = dfAnime['type'].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf81c41",
   "metadata": {},
   "source": [
    "**Se debe tener en cuenta que el dataframe cuenta con animes de todo tipo incluyendo peliculas, esto significa que muchos de los datos se veran alterados por esto, por ejemplo, la cantidad de episodios tiende a ser 1 si el anime es del tipo pelicula mientras que las series pueden llegar incluso a 100 episodios.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b506c20",
   "metadata": {},
   "source": [
    "**Por ello, es apropiado partir el dataframe en 2, uno para series de anime normales y otro para peliculas, ovas, etc.\n",
    "Para evitar un problema demasiado complejo, solo trabajaremos con el dataframe de series. Eliminamos la columna \"type\" puesto que ya no sera de utilidad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ea597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series = dfAnime.loc[dfAnime['type'] == '1']\n",
    "df_series = df_series.drop('type',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff0a3e7",
   "metadata": {},
   "source": [
    "**El dataframe tiene todos los generos de un anime en una sola columna, para que esta informacion sea util, debemos clasificarla**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5401a20e",
   "metadata": {},
   "source": [
    "**Primero observemos que categorias son las mas populares**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d98864",
   "metadata": {},
   "outputs": [],
   "source": [
    "genreCount = df_series[[\"genre\"]]\n",
    "genreCount[\"genre\"] = genreCount[\"genre\"].str.split(\", | , | ,\")\n",
    "genreCount = genreCount.explode(\"genre\")\n",
    "genreCount[\"genre\"] = genreCount[\"genre\"].str.title()\n",
    "\n",
    "print(f'Total unique genres are {len(genreCount[\"genre\"].unique())}')\n",
    "print(f'Occurances of unique genres :')\n",
    "genreCount[\"genre\"].value_counts().to_frame().T.style.set_properties(**{\"background-color\": \"#2a9d8f\",\"color\":\"white\",\"border\": \"1.5px  solid black\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7159ca61",
   "metadata": {},
   "source": [
    "**Ahora, creemos una columna para cada uno de las 15 generos mas populares y eliminemos la columna genres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a392811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNewColumn(colname):\n",
    "    df_series[colname] = np.where(df_series.genre.str.contains(colname),1,0)\n",
    "    df_series[colname] = df_series[colname].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee312cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def containsGenre(dfInfo,word):  \n",
    "    if str(df_series[\"genre\"]).find(word):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ad5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ciclo que se encarga de crear 15 columnas de los generos mas populares\n",
    "for i in range(15):\n",
    "    createNewColumn(genreCount[\"genre\"].value_counts().index.tolist()[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e532905",
   "metadata": {},
   "source": [
    "**Finalmente tenemos el siguiente dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c438d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series = df_series.drop('genre',axis=1)\n",
    "df_series.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688c7d4",
   "metadata": {},
   "source": [
    "## Ajustes para el dataframe rating.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa37ee7",
   "metadata": {},
   "source": [
    "**Para tener certeza de que a un usuario le gusto o no un anime debemos extraer el promedio de sus calificaciones. Si la calificacion dada es mayor o igual a la media, significa que el usuario disfruto del anime, en caso contrario, se considerara una opinion negativa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f577ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRating['ratingMean']=dfRating[\"rating\"].mean()\n",
    "dfRating['Liked']=np.where(dfRating.rating >= dfRating.ratingMean ,1,0)\n",
    "dfRating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8146be66",
   "metadata": {},
   "source": [
    "## **Eliminacion de outliers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc11f3be",
   "metadata": {},
   "source": [
    "**Dada la naturaleza de las variables involucradas, solo tiene sentido analizar los outliers de los episodios y los miembros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680eef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_low = df_series[\"episodes\"].quantile(0.25)\n",
    "q_hi  = df_series[\"episodes\"].quantile(0.75)\n",
    "iqr = q_hi - q_low\n",
    "\n",
    "lower = q_low - (1.5*iqr)\n",
    "high = q_hi + (1.5*iqr)\n",
    "\n",
    "df_series = df_series[(df_series[\"episodes\"] < high) & (df_series[\"episodes\"] > lower)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11262aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_low = df_series[\"members\"].quantile(0.25)\n",
    "q_hi  = df_series[\"members\"].quantile(0.75)\n",
    "iqr = q_hi - q_low\n",
    "\n",
    "lower = q_low - (1.5*iqr)\n",
    "high = q_hi + (1.5*iqr)\n",
    "\n",
    "df_series = df_series[(df_series[\"members\"] < high) & (df_series[\"members\"] > lower)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e61dac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "atr = 'episodes'\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.boxplot(x=df_series[atr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "atr = 'members'\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.boxplot(x=df_series[atr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb7c22b",
   "metadata": {},
   "source": [
    "## Resolucion del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beacbc9f",
   "metadata": {},
   "source": [
    "**Para resolver nuestro problema de recomendacion de anime necesitaremos dos cosas, en primer lugar, unas categorias que clasifiquen adecuadamente los animes del dataframe, una vez hecho esto, usaremos un modelo de clasificacion para adecuar los datos las clasificaciones previamente creadas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2144ec6",
   "metadata": {},
   "source": [
    "## Construccion del modelo de clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be97ed7a",
   "metadata": {},
   "source": [
    "**La Variable \"Slice Of Life genera errores por lo que procedemos a eliminarla**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b5efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series = df_series.drop('Slice Of Life',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9142a1a1",
   "metadata": {},
   "source": [
    "**Ahora procedemos a observar las correlaciones entre los generos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a7bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlacionEntre = list(set(df_series.columns) - set([\"anime_id\",\"name\",\"episodes\",\"rating\",\"members\"]))\n",
    "ax = sns.heatmap(df_series[correlacionEntre].corr(),annot=True,cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1173c461",
   "metadata": {},
   "source": [
    "**Si bien las correlaciones no son muy altas entre si, teniendo en cuenta el contexto de los generos, podemos eliminar algunos generos que pueden ser descritos por otros.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64fa9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series = df_series.drop('Mecha',axis=1)\n",
    "df_series = df_series.drop('Shoujo',axis=1)\n",
    "df_series = df_series.drop('School',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683fff2b",
   "metadata": {},
   "source": [
    "**Para construir un modelo adecuado, decidimos utilizar los generos mas populares y descartar las variables que no seran de demasiada utilidad. Ademas, normalizaremos los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ee0729",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(set(df_series.columns) - set([\"anime_id\",\"name\",\"episodes\"]))\n",
    "\n",
    "rango_de_salida_de_las_variables_escaladas = (0,1)  #Tupla con el siguiente formato: (mínimo deseado, máximo deseado).\n",
    "scaler = MinMaxScaler(feature_range=rango_de_salida_de_las_variables_escaladas)  #Instanciamos el objeto para escalar los datos. \n",
    "\n",
    "df_series_norm = deepcopy(df_series[features])  #Inicializamos este objeto con una copia profunda del las columnas de entrada de interés del dataframe.\n",
    "df_series_norm[features] = scaler.fit_transform(df_series_norm) #Ajustamos y transformamos los datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d8b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "# HYPERPARÁMETROS DEL MODELO\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "kmin              = 1          #Límite inferior para explorar el número de grupos.\n",
    "kmax              = 20          #Límite superior para explorar el número de grupos.\n",
    "init              ='k-means++'  #Se define el método de inicialización. Otra opción válida es 'random'.\n",
    "n_init            = 10          #Número de inicializaciones aleatorias. Al final scikit learn escoge aquel con la menor inercia \n",
    "                                #(i.e.: suma de cuadrados de distancias de cada punto a su centroide respectivo dentro de cada grupo, para todos los puntos). \n",
    "                                #https://scikit-learn.org/stable/modules/clustering.html\n",
    "max_iter          = 300         #Número MÁXIMO de iteraciones para una sola ejecución.\n",
    "random_seed       = 76          #Semilla aleatoria. Permite obtener los mismos resultados en cada ejecución.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cfa60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_norm = df_series_norm\n",
    "# Vamos a dividir los datos en un conjunto de entrenamiento y un conjunto de pruebas.\n",
    "mezclar_los_datos       = True #Vamos a mezclar de forma aleatoria los datos antes de particionarlos. \n",
    "valor_semilla_aleatoria = 76   #Esto es útil si se quiere garantizar la repetibilidad \n",
    "                               #de la partición de datos en ejecuciones sucesivas de su notebook o script.\n",
    "particion_para_pruebas = 0.2\n",
    "\n",
    "#Hacemos la partición para obtener el conjunto de pruebas y el \"resto\" (i.e.: entrenamiento y desarrollo).\n",
    "df_x_train, df_x_test = train_test_split(df_x_norm,                                         \n",
    "                                        test_size=particion_para_pruebas, \n",
    "                                        random_state=valor_semilla_aleatoria, \n",
    "                                        shuffle=mezclar_los_datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3f3610",
   "metadata": {},
   "source": [
    "**Para tener certeza, observemos el metodo de las siluetas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bb909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisemos los resultados del método de la silueta para algunos valores\n",
    "#\"tentativos\" para k:\n",
    "silhouette_score_list        = []\n",
    "\n",
    "for k in [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]:\n",
    "    model3 = KMeans(n_clusters=k,         #Se define el número de grupos.\n",
    "                  init=init,            #Se define el método de inicialización. Otra opción es 'random'\n",
    "                  n_init=n_init,        #Número de inicializaciones aleatorias. Al final se escoge aquel con la menor inercia: sum( (x_i-centroide(x_i))^2 ) \n",
    "                  max_iter=max_iter,    #Número MÁXIMO de iteraciones para una sola ejecución.\n",
    "                  random_state=random_seed)\n",
    "    model3.fit(df_x_train)\n",
    "    sc = silhouette_score(df_x_train.values, model3.labels_)\n",
    "    silhouette_score_list.append(sc)\n",
    "    print(\n",
    "        \"For k clusters =\",\n",
    "        k,\n",
    "        \"The average silhouette_score is :\",\n",
    "        sc,\n",
    "    )\n",
    "    plt.figure(figsize=(10,3))  #Tamaño de la figura (ancho, alto).\n",
    "    visualizer5 = SilhouetteVisualizer(estimator=model3, colors='yellowbrick')\n",
    "    visualizer5.fit(df_x_train)\n",
    "    visualizer5.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3996ba9e",
   "metadata": {},
   "source": [
    "**Observemos graficas que describen los 3 indicadores para KMeans**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = KMeans(init=init,              #Se define el método de inicialización. \n",
    "               n_init=n_init,           #Número de inicializaciones aleatorias. Al final se escoge aquel con la menor inercia: sum( (x_i-centroide(x_i))^2 ). \n",
    "               max_iter=max_iter,       #Número MÁXIMO de iteraciones para una sola ejecución.\n",
    "               random_state=random_seed)\n",
    "\n",
    "for metric in [\"distortion\", \"silhouette\", \"calinski_harabasz\"]:  #Itere sobre las métricas que soporta KElbowVisualizer.\n",
    "  \n",
    "  #Este condicional permite adaptar el flujo pues dos de las métricas requieren al menos 2 grupos para que se puedan calcular.\n",
    "  if metric==\"silhouette\" or metric==\"calinski_harabasz\":  \n",
    "    kmin_ = max(2,kmin)\n",
    "  else:\n",
    "    kmin_ = kmin\n",
    "  \n",
    "  plt.figure(figsize=(10,5))   #Tamaño de la figura (ancho, alto).\n",
    "  visualizer2 = KElbowVisualizer(estimator=model2, \n",
    "                                  k=(kmin_,kmax+1),     #Permite explorar valores de k entre [kmin_,kmax].\n",
    "                                  metric=metric,        #Opciones:  \"distortion\", \"silhouette\", \"calinski_harabasz\"\n",
    "                                  timings=False,          \n",
    "                                  locate_elbow=True)   #Si esta opción se activa, ubica el codo con una línea punteada.\n",
    "  visualizer2.fit(df_x_train)   #Ajusta los datos al visualizador.\n",
    "  visualizer2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c994010",
   "metadata": {},
   "source": [
    "**Los indicadores obtenidos no encuentran un punto de decision para determinar cual valor es el mejor para K, sin embargo, como determinamos un numero de generos, es deseable que los animes se incluyan de una u otra manera en estos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25ac0f8",
   "metadata": {},
   "source": [
    "**Inicialmente teniamos 15 generos pero como observamos, 3 de estos podian ser perfectamente descritos por otros. Por tanto, utilizaremos como valor de K el numero 12**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aaa15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-means\n",
    "#-------------------------------------------------------------------------------\n",
    "k = 12  #Número de grupos que se escogió después del análisis previo.\n",
    "\n",
    "#Ahora se instancia el objeto para utilizar el agrupamiento con k-means.\n",
    "#Para ver todas los opciones del constructor, consulte: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "#Nota: el algoritmo de k-means disponible en scikit-learn funciona únicamente con la distancia euclidiana.\n",
    "#Si requiere aplicar k-means con otras métricas de distancia, puede consultar la librería PyClustering: https://github.com/annoviko/pyclustering\n",
    "kmeans = KMeans(n_clusters   = k,            #Se define el número de grupos.\n",
    "                init         = init,         #Se define el método de inicialización. Otra opción es 'random'\n",
    "                n_init       = n_init,       #Número de inicializaciones aleatorias. \n",
    "                max_iter     = max_iter,     #Número MÁXIMO de iteraciones para una sola ejecución.\n",
    "                random_state = random_seed)\n",
    "\n",
    "#Hagamos el ajuste (i.e.: encontremos los centroides).\n",
    "kmeans.fit(df_x_train)\n",
    "predict = kmeans.predict(df_series_norm)\n",
    "\n",
    "df_series['Classification'] = pd.Series(predict, index=df_series_norm.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0185e9af",
   "metadata": {},
   "source": [
    "**Finalmente el dataframe con el que usaremos la clasificacion es el siguiente:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9b2d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_final = pd.merge(df_series, dfRating, how='inner', left_on = 'anime_id', right_on = 'anime_id')\n",
    "df_final.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa2a5fa",
   "metadata": {},
   "source": [
    "## Probando el filtro de recomendacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c33e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Eliminamos los valores liked=0 ya que no son necesarios en las recomendaciones\n",
    "df_depured=df_final[df_final.Liked != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76b50a9",
   "metadata": {},
   "source": [
    "### Separamos del dataframe, los valores que no fueron del agrado de los usuarios, marcados con liked=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d132047",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Eliminamos las columnas innecesarias\n",
    "df_prepared=df_depured.iloc[:,1:16]\n",
    "df_prepared = df_prepared.drop('episodes', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ec0dc6",
   "metadata": {},
   "source": [
    "## Al fusionar los valores de estos dos animes se debe mantener los valores 1 en las casillas correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd430496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion(name1,name2):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93295c9f",
   "metadata": {},
   "source": [
    "### Quitamos las columnas que no nos sirven para generar la información respectiva de la unión de dos animes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e908b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_depured=df_fusion[df_final.name == \"Uchuu Majin Daikengou\"]\n",
    "df_depured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7dacea",
   "metadata": {},
   "source": [
    "Aqui vemos este anime de ejemplo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4160253",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_depured2=df_fusion[df_final.name == \"Zenmai Zamurai\"]\n",
    "df_depured2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0bfd63",
   "metadata": {},
   "source": [
    "Además de este otro anime de ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f61b9ee",
   "metadata": {},
   "source": [
    "### Así obtenemos las columnas donde el valor es 1, de esta forma permitiendonos categorizar de una manera más sencilla. Además de obtener un promedio de miembros y rating "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e527dfe",
   "metadata": {},
   "source": [
    "## Construccion del modelo de clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcc3339",
   "metadata": {},
   "source": [
    "**Ahora buscamos clasificar las variables, usaremos el algoritmo de KNN (K Nearest Neighbors). Teniendo en cuenta que clasificaremos segun lo obtenido por el modelo de clustering, es logico usar el mismo K obtenido**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a6919",
   "metadata": {},
   "source": [
    "### División del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95812483",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_attr = features\n",
    "target_attr = 'Classification'\n",
    "\n",
    "input_attr.remove('rating') \n",
    "\n",
    "print(input_attr)\n",
    "\n",
    "df_x_knn = deepcopy(df_final[input_attr])\n",
    "df_y_knn = deepcopy(df_final[target_attr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b002738",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix = True\n",
    "seed = 13\n",
    "\n",
    "train_set = 0.6\n",
    "dev_set = 0.2\n",
    "\n",
    "train_dev_set = train_set + dev_set\n",
    "test_set = 1 - train_dev_set\n",
    "\n",
    "df_x_rest_knn, df_x_test_knn, df_y_rest_knn, df_y_test_knn = train_test_split(df_x_knn, df_y_knn, test_size=test_set, random_state=seed, shuffle=mix)\n",
    "\n",
    "df_x_train_knn, df_x_val_knn, df_y_train_knn, df_y_val_knn = train_test_split(df_x_rest_knn, df_y_rest_knn, test_size=dev_set/train_dev_set, random_state=seed, shuffle= not mix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0eea58",
   "metadata": {},
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e934ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 12\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "knn.fit(df_x_train_knn, df_y_train_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_test_knn = knn.predict(df_x_test_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9622090a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "cm_knn = metrics.confusion_matrix(df_y_test_knn,y_predicted_test_knn)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix = cm_knn)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f2d11",
   "metadata": {},
   "source": [
    "### Precisión del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a214a6b3",
   "metadata": {},
   "source": [
    "#### Precisión en el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c94d2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_test = metrics.accuracy_score(df_y_test_knn,y_predicted_test_knn)\n",
    "print('Accuracy on test data: %.4f'% acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b14b7c2",
   "metadata": {},
   "source": [
    "#### Precisión en el conjunto de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf197fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_train_knn = knn.predict(df_x_train_knn)\n",
    "y_predicted_val_knn = knn.predict(df_x_val_knn)\n",
    "acc_train = metrics.accuracy_score(df_y_train_knn,y_predicted_train_knn)\n",
    "print('Accuracy on training data: %.4f'% acc_train)\n",
    "acc_val = metrics.accuracy_score(df_y_val_knn,y_predicted_val_knn)\n",
    "print('Accuracy on validation data: %.4f'% acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81e2e22",
   "metadata": {},
   "source": [
    "#### Ejemplos de predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aba383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value = knn.predict(df_depured[input_attr])\n",
    "\n",
    "print('El valor de clasificación para el dataframe depurado 1 es ',predicted_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95594d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value = knn.predict(df_depured2[input_attr])\n",
    "\n",
    "print('El valor de clasificación para el dataframe depurado 2 es ',predicted_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f96ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df_fusion = knn.predict(df_fusion[input_attr])\n",
    "\n",
    "print('El valor de clasificación para el dataframe fusionado es ',predicted_df_fusion)\n",
    "predicted_df_fusion.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee84e141",
   "metadata": {},
   "source": [
    "#### Dataframe por valor de Clasificación 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb538706",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series_by_7 = df_series[df_series['Classification'] == 7]\n",
    "df_series_by_7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a751ee96",
   "metadata": {},
   "source": [
    "#### Los 5 animes más famosos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9feee706",
   "metadata": {},
   "source": [
    "##### Por rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e37ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df_series_by_7 = df_series_by_7.sort_values(by='rating', ascending=False)\n",
    "rating_df_series_by_7.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b076f123",
   "metadata": {},
   "source": [
    "##### Por miembros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58161f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "members_df_series_by_7 = df_series_by_7.sort_values(by='members', ascending=False)\n",
    "members_df_series_by_7.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec892058",
   "metadata": {},
   "source": [
    "##### Por rating y miembros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e98b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "members_rating_df_series_by_7 = df_series_by_7.sort_values(by=['rating','members'], ascending=False)\n",
    "members_rating_df_series_by_7.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b92378",
   "metadata": {},
   "source": [
    "#### Dataframe por valor de Clasificación 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa9e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_series_by_8 = df_series[df_series['Classification'] == 8]\n",
    "df_series_by_8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75796a2b",
   "metadata": {},
   "source": [
    "#### Los 5 animes más famosos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15346f6",
   "metadata": {},
   "source": [
    "##### Por rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba0ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df_series_by_8 = df_series_by_8.sort_values(by='rating', ascending=False)\n",
    "rating_df_series_by_8.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d61b60c",
   "metadata": {},
   "source": [
    "##### Por miembros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8e77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "members_df_series_by_8 = df_series_by_8.sort_values(by='members', ascending=False)\n",
    "members_df_series_by_8.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd28486",
   "metadata": {},
   "source": [
    "##### Por rating y miembros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47684191",
   "metadata": {},
   "outputs": [],
   "source": [
    "members_rating_df_series_by_8 = df_series_by_8.sort_values(by=['rating','members'], ascending=False)\n",
    "members_rating_df_series_by_8.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4be162d5148c3f7155f657edd2ca5251e2e15f95883412448e943f9efe7bbcf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
